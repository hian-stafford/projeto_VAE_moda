# ðŸ§  VAE com Fashion MNIST â€“ GeraÃ§Ã£o e ReconstruÃ§Ã£o de Imagens com TensorFlow

Este projeto implementa um **Autoencoder Variacional (VAE)** usando a base de dados **Fashion MNIST**, com o objetivo de gerar e reconstruir imagens de artigos de moda de forma realista. Ele utiliza camadas convolucionais e a tÃ©cnica de reparametrizaÃ§Ã£o para criar um modelo probabilÃ­stico poderoso, aplicando princÃ­pios de aprendizado nÃ£o supervisionado.

---

## ðŸ§© VisÃ£o Geral

- ðŸŽ¯ **Objetivo:** Demonstrar o uso de um VAE com camadas convolucionais para gerar imagens sintÃ©ticas e realizar reconstruÃ§Ã£o de imagens reais.
- ðŸ§ª **Base de Dados:** [Fashion MNIST](https://github.com/zalandoresearch/fashion-mnist) â€” 70.000 imagens em escala de cinza de 28x28 pixels representando roupas e acessÃ³rios.
- âš™ï¸ **TÃ©cnicas Utilizadas:**
  - Convolutional Variational Autoencoder (CVAE)
  - ReparametrizaÃ§Ã£o (z = Î¼ + Ïƒ * Îµ)
  - Loss personalizada combinando **Binary Crossentropy** + **KL Divergence**
  - VisualizaÃ§Ã£o de aprendizado e amostragem de espaÃ§o latente
  - MediÃ§Ã£o de tempo de treinamento por batch

---

## ðŸ› ï¸ Ferramentas e Tecnologias

| Tecnologia | FunÃ§Ã£o |
|------------|--------|
| Python 3.x | Linguagem principal |
| TensorFlow / Keras | Framework de Deep Learning |
| NumPy | ManipulaÃ§Ã£o de arrays |
| Matplotlib | VisualizaÃ§Ã£o de dados |
| Fashion MNIST | Dataset de benchmark |

---

## ðŸ“š Conceitos Importantes

### ðŸ” O que Ã© um VAE?

Um **Variational Autoencoder (VAE)** Ã© uma rede neural generativa que aprende uma representaÃ§Ã£o **probabilÃ­stica** dos dados. Ele codifica os dados de entrada em uma distribuiÃ§Ã£o latente, permitindo a geraÃ§Ã£o de novas amostras similares Ã s originais.

### âš–ï¸ FunÃ§Ã£o de Perda

A perda total do modelo combina:

- **Reconstruction Loss:** Mede quÃ£o parecida a imagem reconstruÃ­da Ã© com a original (via Binary Crossentropy).
- **KL Divergence:** Penaliza desvios da distribuiÃ§Ã£o latente aprendida em relaÃ§Ã£o a uma distribuiÃ§Ã£o normal padrÃ£o.

---

## ðŸ–¼ï¸ Exemplos de Resultados

### ðŸŽ² Amostras SintÃ©ticas

#### ðŸ”· Amostra SintÃ©tica Ãšnica
![img_sintetica_unica](https://github.com/user-attachments/assets/60fabe6e-c4cc-49fb-b454-70d47e18183e)

#### ðŸ”¶ 256 Amostras SIntÃ©ticas AleatÃ³rias
![img_sinteticas](https://github.com/user-attachments/assets/b519dbaf-552e-46e1-90d8-5c9976d142ff)

---

## ðŸ’¡ AplicaÃ§Ãµes Reais

- **CompressÃ£o de imagens**
- **RemoÃ§Ã£o de ruÃ­do**
- **GeraÃ§Ã£o de conteÃºdo visual**
- **AnÃ¡lise de anomalias em imagens**
- **Base para modelos de transferÃªncia de estilo**

---

## ðŸ“ˆ MÃ©tricas de Desempenho

Durante o treinamento, foram monitoradas:

- `total_loss` (perda total)
- `ce_loss` (reconstruction loss)
- `kl_loss` (KL divergence loss)
- `training_time` (tempo por batch)

Essas mÃ©tricas ajudam a compreender o comportamento do modelo ao longo das Ã©pocas e verificar se ele estÃ¡ aprendendo uma distribuiÃ§Ã£o significativa.
---

## ðŸ“§ Contato

- ðŸ“Œ **Autor**: Hian Stafford
- ðŸ“© **Email**: hian.correa@gmail.com
```text
  /\_/\  
 ( -.- ) 
  > ^ < 
```
